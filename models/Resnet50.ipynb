{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VRn_8Ud_C-yo"},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3606,"status":"ok","timestamp":1667396644116,"user":{"displayName":"Polina Leontyeva","userId":"17205654022728299606"},"user_tz":-180},"id":"0p6nWxlYD8Zn","outputId":"761cf603-d264-44e6-8da9-06a263ce797c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n","Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.12.1+cu113)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.1.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n"]}],"source":["!pip install torchvision"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4207,"status":"ok","timestamp":1667396648303,"user":{"displayName":"Polina Leontyeva","userId":"17205654022728299606"},"user_tz":-180},"id":"t_nFVuO4D95l","outputId":"bef3d07c-7364-4df8-cc58-3c8d621dec34"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboardcolab\n","  Downloading tensorboardcolab-0.0.22.tar.gz (2.5 kB)\n","Building wheels for collected packages: tensorboardcolab\n","  Building wheel for tensorboardcolab (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorboardcolab: filename=tensorboardcolab-0.0.22-py3-none-any.whl size=3859 sha256=a001215186ecec5f54549175bd107e14a7ce1061508ebbb385fafb3050db8c75\n","  Stored in directory: /root/.cache/pip/wheels/69/4e/4a/1c6c267395cb10edded1050df12af165d3254cfce324e80941\n","Successfully built tensorboardcolab\n","Installing collected packages: tensorboardcolab\n","Successfully installed tensorboardcolab-0.0.22\n"]}],"source":["!pip install tensorboardcolab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18496,"status":"ok","timestamp":1667396666790,"user":{"displayName":"Polina Leontyeva","userId":"17205654022728299606"},"user_tz":-180},"id":"19slM5znD6BV","outputId":"c32cd804-5974-4f66-9ae3-64f9e358b572"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wUj-w7ToAFEz"},"outputs":[],"source":["path_to_zip_file = \"/content/gdrive/MyDrive/ethnicity/fairface-img-margin025-trainval.zip\"\n","directory_to_extract_to = \"/content/data/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Mm8tKVJ7ADqc"},"outputs":[],"source":["import zipfile\n","with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n","    zip_ref.extractall(directory_to_extract_to)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KHL_zZvl8Az1","outputId":"ca09dc02-540b-406e-c4bd-c48eb5c4504c"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-bf7d6b6d182d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataset_loader'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["from torchvision import models\n","import torch\n","from torchvision import transforms\n","from PIL import Image\n","from dataset_loader import gen_dataloader\n","import time\n","import copy\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import os\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm import tqdm\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"A4noCkL41Ssw"},"outputs":[],"source":["writer = SummaryWriter()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JWOQnqFd6bbM"},"outputs":[],"source":["train_data_path = \"/content/data/train/\"\n","val_data_path = \"/content/data/val/\"\n","models_path = \"/content/gdrive/MyDrive/ethnicity/models/\"\n","train_labels_path = \"/content/gdrive/MyDrive/ethnicity/fairface_label_train.csv\"\n","val_labels_path = \"/content/gdrive/MyDrive/ethnicity/fairface_label_val.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fYrrSjkl8u1b"},"outputs":[],"source":["data_transforms = {\n","    'train': transforms.Compose([\n","        #transforms.ToPILImage(),\n","        transforms.RandomResizedCrop(224), # проверить кроп \n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        #transforms.ToPILImage(),\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"k2e8qLzybNhA"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qDdaFEsr7LLu"},"outputs":[],"source":["tb = None"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PPXywkIK9y70"},"outputs":[],"source":["def train_model(model, dataloaders, criterion, optimizer, scheduler, dataset_sizes, num_epochs=25, tb=tb, log_interval=10):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch}/{num_epochs - 1}')\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for batch_idx, (inputs, labels) in tqdm(enumerate(dataloaders[phase])):\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","                if batch_idx % log_interval == 0:\n","  \n","                  # This is where I'm recording to Tensorboard\n","                  #tb.save_value('Train Loss', 'train_loss', self.globaliter, loss.item())\n","                  writer.add_scalar(\"Loss/train\", loss.item(), batch_idx)\n","                  print(f'{batch_idx} Loss: {loss.item():.4f}')\n","\n","\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","\n","    time_elapsed = time.time() - since\n","    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n","    print(f'Best val Acc: {best_acc:4f}')\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3qtA7ntVcVLw"},"outputs":[],"source":["dataloader_train, train_size, classes = gen_dataloader(train_data_path, train_labels_path,\n","                            transformers=data_transforms[\"train\"], batch_size=128)\n","\n","dataloader_val, val_size, classes = gen_dataloader(val_data_path, val_labels_path,\n","                            transformers=data_transforms[\"val\"], batch_size=128)\n","\n","dataloaders = {\n","    \"train\": dataloader_train,\n","    \"val\": dataloader_val\n","}\n","dataset_sizes = {'train': train_size, 'val': val_size}\n","dataset_sizes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4MsvoVDVcmAK"},"outputs":[],"source":["model_ft = models.resnet50(pretrained=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jblo4RzKc-VK"},"outputs":[],"source":["# !tensorboard --logdir=runs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"FZ8dI7PlcwRD"},"outputs":[],"source":["# num_ftrs = model_ft.fc.in_features\n","# # Here the size of each output sample is set to 2.\n","# # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n","# model_ft.fc = nn.Linear(num_ftrs, len(classes))\n","\n","for param in model_ft.parameters():\n","    param.requires_grad = False\n","\n","model_ft.fc = nn.Sequential(\n","    nn.Linear(2048, 128),\n","    nn.ReLU(inplace=True),\n","    nn.Linear(128, len(classes))).to(device)\n","\n","model_ft = model_ft.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","# Observe that all parameters are being optimized\n","optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9) # Проверить lr/ переделать на adam\n","\n","# Decay LR by a factor of 0.1 every 7 epochs\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1) # Попробовать убрать"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Np0KeG6Xc5RM"},"outputs":[],"source":["model_ft = train_model(model_ft, dataloaders, criterion, optimizer_ft, exp_lr_scheduler,\n","                       dataset_sizes, num_epochs=25)\n","writer.flush()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pj6ZDL_rdpTM"},"outputs":[],"source":["model_ft.save(os.path.join(models_path, \"model_25.pth\"))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}